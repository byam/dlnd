{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-20bcfb28f594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter a file name: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     num_epochs = int(raw_input(\n\u001b[1;32m    160\u001b[0m         \"Enter the number of epochs to run for: \"))\n",
      "\u001b[0;32m/Users/01014477/anaconda3/envs/p2/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/01014477/anaconda3/envs/p2/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "overfitting\n",
    "~~~~~~~~~~~\n",
    "Plot graphs to illustrate the problem of overfitting.  \n",
    "\"\"\"\n",
    "\n",
    "# Standard library\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# My library\n",
    "sys.path.append('../src/')\n",
    "import mnist_loader\n",
    "import network2\n",
    "\n",
    "# Third-party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def main(filename, num_epochs,\n",
    "         training_cost_xmin=200, \n",
    "         test_accuracy_xmin=200, \n",
    "         test_cost_xmin=0, \n",
    "         training_accuracy_xmin=0,\n",
    "         training_set_size=1000, \n",
    "         lmbda=0.0):\n",
    "    \"\"\"``filename`` is the name of the file where the results will be\n",
    "    stored.  ``num_epochs`` is the number of epochs to train for.\n",
    "    ``training_set_size`` is the number of images to train on.\n",
    "    ``lmbda`` is the regularization parameter.  The other parameters\n",
    "    set the epochs at which to start plotting on the x axis.\n",
    "    \"\"\"\n",
    "    run_network(filename, num_epochs, training_set_size, lmbda)\n",
    "    make_plots(filename, num_epochs, \n",
    "               test_accuracy_xmin,\n",
    "               training_cost_xmin,\n",
    "               test_accuracy_xmin, \n",
    "               training_accuracy_xmin,\n",
    "               training_set_size)\n",
    "                       \n",
    "def run_network(filename, num_epochs, training_set_size=1000, lmbda=0.0):\n",
    "    \"\"\"Train the network for ``num_epochs`` on ``training_set_size``\n",
    "    images, and store the results in ``filename``.  Those results can\n",
    "    later be used by ``make_plots``.  Note that the results are stored\n",
    "    to disk in large part because it's convenient not to have to\n",
    "    ``run_network`` each time we want to make a plot (it's slow).\n",
    "    \"\"\"\n",
    "    # Make results more easily reproducible\n",
    "    random.seed(12345678)\n",
    "    np.random.seed(12345678)\n",
    "    training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "    net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost())\n",
    "    net.large_weight_initializer()\n",
    "    test_cost, test_accuracy, training_cost, training_accuracy \\\n",
    "        = net.SGD(training_data[:training_set_size], num_epochs, 10, 0.5,\n",
    "                  evaluation_data=test_data, lmbda = lmbda,\n",
    "                  monitor_evaluation_cost=True, \n",
    "                  monitor_evaluation_accuracy=True, \n",
    "                  monitor_training_cost=True, \n",
    "                  monitor_training_accuracy=True)\n",
    "    f = open(filename, \"w\")\n",
    "    json.dump([test_cost, test_accuracy, training_cost, training_accuracy], f)\n",
    "    f.close()\n",
    "\n",
    "def make_plots(filename, num_epochs, \n",
    "               training_cost_xmin=200, \n",
    "               test_accuracy_xmin=200, \n",
    "               test_cost_xmin=0, \n",
    "               training_accuracy_xmin=0,\n",
    "               training_set_size=1000):\n",
    "    \"\"\"Load the results from ``filename``, and generate the corresponding\n",
    "    plots. \"\"\"\n",
    "    f = open(filename, \"r\")\n",
    "    test_cost, test_accuracy, training_cost, training_accuracy \\\n",
    "        = json.load(f)\n",
    "    f.close()\n",
    "    plot_training_cost(training_cost, num_epochs, training_cost_xmin)\n",
    "    plot_test_accuracy(test_accuracy, num_epochs, test_accuracy_xmin)\n",
    "    plot_test_cost(test_cost, num_epochs, test_cost_xmin)\n",
    "    plot_training_accuracy(training_accuracy, num_epochs, \n",
    "                           training_accuracy_xmin, training_set_size)\n",
    "    plot_overlay(test_accuracy, training_accuracy, num_epochs,\n",
    "                 min(test_accuracy_xmin, training_accuracy_xmin),\n",
    "                 training_set_size)\n",
    "\n",
    "def plot_training_cost(training_cost, num_epochs, training_cost_xmin):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(np.arange(training_cost_xmin, num_epochs), \n",
    "            training_cost[training_cost_xmin:num_epochs],\n",
    "            color='#2A6EA6')\n",
    "    ax.set_xlim([training_cost_xmin, num_epochs])\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_title('Cost on the training data')\n",
    "    plt.show()\n",
    "\n",
    "def plot_test_accuracy(test_accuracy, num_epochs, test_accuracy_xmin):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(np.arange(test_accuracy_xmin, num_epochs), \n",
    "            [accuracy/100.0 \n",
    "             for accuracy in test_accuracy[test_accuracy_xmin:num_epochs]],\n",
    "            color='#2A6EA6')\n",
    "    ax.set_xlim([test_accuracy_xmin, num_epochs])\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_title('Accuracy (%) on the test data')\n",
    "    plt.show()\n",
    "\n",
    "def plot_test_cost(test_cost, num_epochs, test_cost_xmin):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(np.arange(test_cost_xmin, num_epochs), \n",
    "            test_cost[test_cost_xmin:num_epochs],\n",
    "            color='#2A6EA6')\n",
    "    ax.set_xlim([test_cost_xmin, num_epochs])\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_title('Cost on the test data')\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_accuracy(training_accuracy, num_epochs, \n",
    "                           training_accuracy_xmin, training_set_size):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(np.arange(training_accuracy_xmin, num_epochs), \n",
    "            [accuracy*100.0/training_set_size \n",
    "             for accuracy in training_accuracy[training_accuracy_xmin:num_epochs]],\n",
    "            color='#2A6EA6')\n",
    "    ax.set_xlim([training_accuracy_xmin, num_epochs])\n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_title('Accuracy (%) on the training data')\n",
    "    plt.show()\n",
    "\n",
    "def plot_overlay(test_accuracy, training_accuracy, num_epochs, xmin,\n",
    "                 training_set_size):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(np.arange(xmin, num_epochs), \n",
    "            [accuracy/100.0 for accuracy in test_accuracy], \n",
    "            color='#2A6EA6',\n",
    "            label=\"Accuracy on the test data\")\n",
    "    ax.plot(np.arange(xmin, num_epochs), \n",
    "            [accuracy*100.0/training_set_size \n",
    "             for accuracy in training_accuracy], \n",
    "            color='#FFA933',\n",
    "            label=\"Accuracy on the training data\")\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim([xmin, num_epochs])\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylim([90, 100])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = raw_input(\"Enter a file name: \")\n",
    "    num_epochs = int(raw_input(\n",
    "        \"Enter the number of epochs to run for: \"))\n",
    "    training_cost_xmin = int(raw_input(\n",
    "        \"training_cost_xmin (suggest 200): \"))\n",
    "    test_accuracy_xmin = int(raw_input(\n",
    "        \"test_accuracy_xmin (suggest 200): \"))\n",
    "    test_cost_xmin = int(raw_input(\n",
    "        \"test_cost_xmin (suggest 0): \"))\n",
    "    training_accuracy_xmin = int(raw_input(\n",
    "        \"training_accuracy_xmin (suggest 0): \"))\n",
    "    training_set_size = int(raw_input(\n",
    "        \"Training set size (suggest 1000): \"))\n",
    "    lmbda = float(raw_input(\n",
    "        \"Enter the regularization parameter, lambda (suggest: 5.0): \"))\n",
    "    main(filename, num_epochs, training_cost_xmin, \n",
    "         test_accuracy_xmin, test_cost_xmin, training_accuracy_xmin,\n",
    "         training_set_size, lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: 3.01079498147\n",
      "Accuracy on training data: 674 / 1000\n",
      "Cost on evaluation data: 2.2699218986\n",
      "Accuracy on evaluation data: 5650 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Cost on training data: 2.4719704957\n",
      "Accuracy on training data: 783 / 1000\n",
      "Cost on evaluation data: 1.81869112249\n",
      "Accuracy on evaluation data: 6739 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Cost on training data: 2.25279857338\n",
      "Accuracy on training data: 834 / 1000\n",
      "Cost on evaluation data: 1.70307657958\n",
      "Accuracy on evaluation data: 7113 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Cost on training data: 2.04082074792\n",
      "Accuracy on training data: 882 / 1000\n",
      "Cost on evaluation data: 1.52891376888\n",
      "Accuracy on evaluation data: 7522 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Cost on training data: 1.91954659759\n",
      "Accuracy on training data: 905 / 1000\n",
      "Cost on evaluation data: 1.48246218956\n",
      "Accuracy on evaluation data: 7616 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Cost on training data: 1.84621647407\n",
      "Accuracy on training data: 902 / 1000\n",
      "Cost on evaluation data: 1.42483601993\n",
      "Accuracy on evaluation data: 7702 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Cost on training data: 1.75373791677\n",
      "Accuracy on training data: 932 / 1000\n",
      "Cost on evaluation data: 1.40186989372\n",
      "Accuracy on evaluation data: 7814 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Cost on training data: 1.6516792245\n",
      "Accuracy on training data: 943 / 1000\n",
      "Cost on evaluation data: 1.36295289309\n",
      "Accuracy on evaluation data: 7905 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Cost on training data: 1.59223247076\n",
      "Accuracy on training data: 944 / 1000\n",
      "Cost on evaluation data: 1.32551167084\n",
      "Accuracy on evaluation data: 7927 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Cost on training data: 1.54181923885\n",
      "Accuracy on training data: 957 / 1000\n",
      "Cost on evaluation data: 1.33821137426\n",
      "Accuracy on evaluation data: 7941 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Cost on training data: 1.49117365297\n",
      "Accuracy on training data: 967 / 1000\n",
      "Cost on evaluation data: 1.33120848331\n",
      "Accuracy on evaluation data: 7984 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Cost on training data: 1.45404547446\n",
      "Accuracy on training data: 965 / 1000\n",
      "Cost on evaluation data: 1.32731765903\n",
      "Accuracy on evaluation data: 7991 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Cost on training data: 1.39915486436\n",
      "Accuracy on training data: 977 / 1000\n",
      "Cost on evaluation data: 1.30316675846\n",
      "Accuracy on evaluation data: 8023 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Cost on training data: 1.3740058987\n",
      "Accuracy on training data: 975 / 1000\n",
      "Cost on evaluation data: 1.2839877999\n",
      "Accuracy on evaluation data: 8094 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Cost on training data: 1.3358461536\n",
      "Accuracy on training data: 982 / 1000\n",
      "Cost on evaluation data: 1.28320773266\n",
      "Accuracy on evaluation data: 8078 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Cost on training data: 1.30435291142\n",
      "Accuracy on training data: 985 / 1000\n",
      "Cost on evaluation data: 1.28676755064\n",
      "Accuracy on evaluation data: 8108 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Cost on training data: 1.28623595803\n",
      "Accuracy on training data: 987 / 1000\n",
      "Cost on evaluation data: 1.29044035455\n",
      "Accuracy on evaluation data: 8114 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Cost on training data: 1.25801742184\n",
      "Accuracy on training data: 984 / 1000\n",
      "Cost on evaluation data: 1.28161242777\n",
      "Accuracy on evaluation data: 8138 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Cost on training data: 1.24018345919\n",
      "Accuracy on training data: 986 / 1000\n",
      "Cost on evaluation data: 1.27606094041\n",
      "Accuracy on evaluation data: 8143 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Cost on training data: 1.22165225826\n",
      "Accuracy on training data: 992 / 1000\n",
      "Cost on evaluation data: 1.2969308208\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Cost on training data: 1.19632267752\n",
      "Accuracy on training data: 990 / 1000\n",
      "Cost on evaluation data: 1.27625466057\n",
      "Accuracy on evaluation data: 8159 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Cost on training data: 1.17609791738\n",
      "Accuracy on training data: 989 / 1000\n",
      "Cost on evaluation data: 1.27140221776\n",
      "Accuracy on evaluation data: 8167 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Cost on training data: 1.16519468639\n",
      "Accuracy on training data: 994 / 1000\n",
      "Cost on evaluation data: 1.290328596\n",
      "Accuracy on evaluation data: 8173 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Cost on training data: 1.14693335127\n",
      "Accuracy on training data: 993 / 1000\n",
      "Cost on evaluation data: 1.26788847012\n",
      "Accuracy on evaluation data: 8198 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Cost on training data: 1.13026631023\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.27009858909\n",
      "Accuracy on evaluation data: 8209 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Cost on training data: 1.11748227993\n",
      "Accuracy on training data: 994 / 1000\n",
      "Cost on evaluation data: 1.29057944411\n",
      "Accuracy on evaluation data: 8195 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Cost on training data: 1.10014444942\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.2815944816\n",
      "Accuracy on evaluation data: 8202 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Cost on training data: 1.08902051828\n",
      "Accuracy on training data: 994 / 1000\n",
      "Cost on evaluation data: 1.2915167008\n",
      "Accuracy on evaluation data: 8196 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Cost on training data: 1.07682723977\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.2852088986\n",
      "Accuracy on evaluation data: 8213 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Cost on training data: 1.06205938224\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.26942349242\n",
      "Accuracy on evaluation data: 8239 / 10000\n",
      "\n",
      "Epoch 30 training complete\n",
      "Cost on training data: 1.05075476465\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.2718552881\n",
      "Accuracy on evaluation data: 8226 / 10000\n",
      "\n",
      "Epoch 31 training complete\n",
      "Cost on training data: 1.04207945851\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.26720689684\n",
      "Accuracy on evaluation data: 8201 / 10000\n",
      "\n",
      "Epoch 32 training complete\n",
      "Cost on training data: 1.02635015622\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.27624467756\n",
      "Accuracy on evaluation data: 8226 / 10000\n",
      "\n",
      "Epoch 33 training complete\n",
      "Cost on training data: 1.01577523178\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.26847655816\n",
      "Accuracy on evaluation data: 8247 / 10000\n",
      "\n",
      "Epoch 34 training complete\n",
      "Cost on training data: 1.00445747437\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.27764800907\n",
      "Accuracy on evaluation data: 8234 / 10000\n",
      "\n",
      "Epoch 35 training complete\n",
      "Cost on training data: 0.995430802335\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.28508112426\n",
      "Accuracy on evaluation data: 8237 / 10000\n",
      "\n",
      "Epoch 36 training complete\n",
      "Cost on training data: 0.98288794921\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.28224852081\n",
      "Accuracy on evaluation data: 8231 / 10000\n",
      "\n",
      "Epoch 37 training complete\n",
      "Cost on training data: 0.972491626224\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.27530136737\n",
      "Accuracy on evaluation data: 8251 / 10000\n",
      "\n",
      "Epoch 38 training complete\n",
      "Cost on training data: 0.963772159642\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.27998550514\n",
      "Accuracy on evaluation data: 8242 / 10000\n",
      "\n",
      "Epoch 39 training complete\n",
      "Cost on training data: 0.952945493681\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.26530776174\n",
      "Accuracy on evaluation data: 8255 / 10000\n",
      "\n",
      "Epoch 40 training complete\n",
      "Cost on training data: 0.943764146431\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.26228723557\n",
      "Accuracy on evaluation data: 8256 / 10000\n",
      "\n",
      "Epoch 41 training complete\n",
      "Cost on training data: 0.933239128273\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.27263794456\n",
      "Accuracy on evaluation data: 8260 / 10000\n",
      "\n",
      "Epoch 42 training complete\n",
      "Cost on training data: 0.924181861499\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.26707323454\n",
      "Accuracy on evaluation data: 8258 / 10000\n",
      "\n",
      "Epoch 43 training complete\n",
      "Cost on training data: 0.914716146652\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.26884807628\n",
      "Accuracy on evaluation data: 8271 / 10000\n",
      "\n",
      "Epoch 44 training complete\n",
      "Cost on training data: 0.905922993102\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.25856385319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on evaluation data: 8276 / 10000\n",
      "\n",
      "Epoch 45 training complete\n",
      "Cost on training data: 0.896956614761\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.27379387626\n",
      "Accuracy on evaluation data: 8276 / 10000\n",
      "\n",
      "Epoch 46 training complete\n",
      "Cost on training data: 0.887640502327\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.26783100762\n",
      "Accuracy on evaluation data: 8269 / 10000\n",
      "\n",
      "Epoch 47 training complete\n",
      "Cost on training data: 0.879154830722\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 1.2598214456\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-65bf31013459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mevaluation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m monitor_evaluation_cost=True, monitor_evaluation_accuracy=True, monitor_training_cost=True, monitor_training_accuracy=True)\n\u001b[0m",
      "\u001b[0;32m/Users/01014477/git/dev/dlnd/neural-networks-and-deep-learning/src/network2.pyc\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, lmbda, evaluation_data, monitor_evaluation_cost, monitor_evaluation_accuracy, monitor_training_cost, monitor_training_accuracy)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Cost on evaluation data: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmonitor_evaluation_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0mevaluation_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 print \"Accuracy on evaluation data: {} / {}\".format(\n",
      "\u001b[0;32m/Users/01014477/git/dev/dlnd/neural-networks-and-deep-learning/src/network2.pyc\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self, data, convert)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             results = [(np.argmax(self.feedforward(x)), y)\n\u001b[0;32m--> 271\u001b[0;31m                         for (x, y) in data]\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/01014477/git/dev/dlnd/neural-networks-and-deep-learning/src/network2.pyc\u001b[0m in \u001b[0;36mfeedforward\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"Return the output of the network if ``a`` is input.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mnist_loader \n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper() \n",
    "\n",
    "import network2 \n",
    "net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)\n",
    "net.large_weight_initializer()\n",
    "net.SGD(training_data[:1000], 400, 10, 0.5,\n",
    "\n",
    "evaluation_data=test_data, lmbda = 0.1,\n",
    "monitor_evaluation_cost=True, monitor_evaluation_accuracy=True, monitor_training_cost=True, monitor_training_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 -Loss: 76541.9219 Validation Accuracy: 0.109375\n",
      "Epoch  1, Batch   2 -Loss: 60458.9609 Validation Accuracy: 0.117188\n",
      "Epoch  1, Batch   3 -Loss: 44314.6562 Validation Accuracy: 0.148438\n",
      "Epoch  1, Batch   4 -Loss: 39902.4219 Validation Accuracy: 0.164062\n",
      "Epoch  1, Batch   5 -Loss: 37721.3633 Validation Accuracy: 0.164062\n",
      "Epoch  1, Batch   6 -Loss: 31761.5664 Validation Accuracy: 0.171875\n",
      "Epoch  1, Batch   7 -Loss: 27462.1445 Validation Accuracy: 0.156250\n",
      "Epoch  1, Batch   8 -Loss: 26282.5469 Validation Accuracy: 0.171875\n",
      "Epoch  1, Batch   9 -Loss: 24186.6816 Validation Accuracy: 0.164062\n",
      "Epoch  1, Batch  10 -Loss: 21562.5371 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch  11 -Loss: 22019.5352 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch  12 -Loss: 22126.3125 Validation Accuracy: 0.210938\n",
      "Epoch  1, Batch  13 -Loss: 20120.9922 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch  14 -Loss: 19451.9414 Validation Accuracy: 0.242188\n",
      "Epoch  1, Batch  15 -Loss: 22087.6973 Validation Accuracy: 0.242188\n",
      "Epoch  1, Batch  16 -Loss: 18655.7656 Validation Accuracy: 0.246094\n",
      "Epoch  1, Batch  17 -Loss: 17159.3535 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  18 -Loss: 15242.6133 Validation Accuracy: 0.289062\n",
      "Epoch  1, Batch  19 -Loss: 17893.6914 Validation Accuracy: 0.316406\n",
      "Epoch  1, Batch  20 -Loss: 19072.5312 Validation Accuracy: 0.316406\n",
      "Epoch  1, Batch  21 -Loss: 15638.3672 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  22 -Loss: 17675.1777 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  23 -Loss: 13880.4141 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  24 -Loss: 15683.6240 Validation Accuracy: 0.382812\n",
      "Epoch  1, Batch  25 -Loss: 13553.9766 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  26 -Loss: 14275.3232 Validation Accuracy: 0.382812\n",
      "Epoch  1, Batch  27 -Loss: 11990.6055 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  28 -Loss: 16020.8711 Validation Accuracy: 0.367188\n",
      "Epoch  1, Batch  29 -Loss: 13472.2578 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  30 -Loss: 12790.9170 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  31 -Loss: 12884.7227 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  32 -Loss: 11043.6592 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  33 -Loss: 12179.9004 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  34 -Loss: 13027.2275 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  35 -Loss: 11796.7080 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  36 -Loss: 12722.0625 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  37 -Loss: 10730.2734 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  38 -Loss: 11044.3613 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  39 -Loss: 11549.3408 Validation Accuracy: 0.453125\n",
      "Epoch  1, Batch  40 -Loss:  9869.4570 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  41 -Loss: 11505.9941 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  42 -Loss:  9596.2637 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  43 -Loss:  8157.1494 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  44 -Loss:  9702.1973 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  45 -Loss: 10429.4648 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  46 -Loss: 10236.6992 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  47 -Loss: 10683.3711 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  48 -Loss:  9189.3672 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  49 -Loss:  7687.4697 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  50 -Loss:  9560.7715 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  51 -Loss:  6954.3535 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  52 -Loss:  9107.8359 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  53 -Loss:  9258.7012 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  54 -Loss:  8653.8350 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  55 -Loss:  7320.5107 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  56 -Loss:  7954.5117 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  57 -Loss:  7178.3877 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  58 -Loss:  8544.2207 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  59 -Loss:  8079.2773 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  60 -Loss:  8370.1074 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  61 -Loss:  8235.7285 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  62 -Loss:  5761.8447 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch  63 -Loss:  7729.6504 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  64 -Loss:  6407.6104 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch  65 -Loss:  6656.0605 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch  66 -Loss:  7842.0703 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch  67 -Loss:  6361.7886 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch  68 -Loss:  7815.6230 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  69 -Loss:  6992.6567 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  70 -Loss:  7425.6514 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  71 -Loss:  4308.7139 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch  72 -Loss:  6580.4043 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch  73 -Loss:  5626.0073 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch  74 -Loss:  7291.6885 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch  75 -Loss:  6088.7559 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch  76 -Loss:  7656.1318 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch  77 -Loss:  6180.6826 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch  78 -Loss:  7474.1123 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch  79 -Loss:  6462.7432 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch  80 -Loss:  6540.1924 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch  81 -Loss:  7020.1299 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch  82 -Loss:  7228.2251 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch  83 -Loss:  5118.7002 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch  84 -Loss:  6945.1841 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch  85 -Loss:  4512.7979 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch  86 -Loss:  5208.3833 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch  87 -Loss:  5362.7891 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch  88 -Loss:  6654.3545 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch  89 -Loss:  5305.6509 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch  90 -Loss:  6123.5962 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch  91 -Loss:  5149.8921 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch  92 -Loss:  4779.5059 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch  93 -Loss:  6884.3247 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch  94 -Loss:  6089.9707 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch  95 -Loss:  4230.0659 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch  96 -Loss:  5944.5420 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch  97 -Loss:  4174.2998 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch  98 -Loss:  5205.4561 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch  99 -Loss:  4737.0527 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 100 -Loss:  4538.8154 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 101 -Loss:  5814.0088 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 102 -Loss:  5343.3872 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 103 -Loss:  5014.4189 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 104 -Loss:  5293.4717 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 105 -Loss:  4601.1079 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 106 -Loss:  3995.8774 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 107 -Loss:  4927.9141 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 108 -Loss:  4372.3701 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 109 -Loss:  6021.6084 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 110 -Loss:  3690.8237 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 111 -Loss:  5411.1660 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 112 -Loss:  3782.5662 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 113 -Loss:  4086.6562 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 114 -Loss:  5513.2832 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 115 -Loss:  4912.0293 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 116 -Loss:  5350.4648 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 117 -Loss:  4087.7402 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 118 -Loss:  4326.7510 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 119 -Loss:  3710.0457 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 120 -Loss:  3827.4846 Validation Accuracy: 0.671875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a0a709d70f6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 keep_prob: 1.})\n\u001b[0m\u001b[1;32m     37\u001b[0m             valid_acc = sess.run(accuracy, feed_dict={\n\u001b[1;32m     38\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_valid_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf. global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} -'\n",
    "                  'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Setup the strides, padding and filter weight/bias such that\n",
    "the output shape is (1, 2, 2, 3).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
    "    F_W = tf.Variable(tf.float32)\n",
    "    F_b = tf.Variable(tf.float32, tf.zeros([]))\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [?, ?, ?, ?]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'SAME'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n",
    "\n",
    "out = conv2d(X)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
